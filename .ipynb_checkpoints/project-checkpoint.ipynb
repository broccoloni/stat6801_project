{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748cb922-37aa-42c8-813d-e025f8746e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch scikit-learn pandas IProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced923ad-de95-41ec-9216-a2c0884fae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417b6922-2732-46f1-b230-b430e7418690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broccoloni/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "distilbert = DistilBertModel.from_pretrained(model_name)\n",
    "distilbert.to(device)\n",
    "distilbert.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdce09e-552f-496b-8b91-45ae3ca54eb6",
   "metadata": {},
   "source": [
    "# Convert PDF to text and extract sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8c467af0-a166-4cbd-acac-5698ab367070",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"RSM.pdf\"\n",
    "\n",
    "pages = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        if text is None:\n",
    "            text = \"\"\n",
    "        pages.append(text)\n",
    "\n",
    "full_text = \"\\n\\n\".join(pages)\n",
    "table_of_contents = full_text[3250:20000].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "eaea942a-a622-4755-8727-bb81733a7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSection(line):\n",
    "    elems = line.split(' ')\n",
    "    if not line or len(elems) == 0:\n",
    "        return False\n",
    "    if elems[0][0].isnumeric():\n",
    "        return True\n",
    "    elif elems[0] == 'Appendix':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getSectionMeta(section):\n",
    "    multi_line_section_map = {\n",
    "        '2.2.3': 17,\n",
    "        '2.3.4.1': 22,\n",
    "        '2.3.6': 22,\n",
    "        '2.4.6': 35,\n",
    "        '2.4.14.4': 54,\n",
    "        'Appendix 4': 71,\n",
    "    }\n",
    "    \n",
    "    removed_page = section[:-2]\n",
    "    elems = removed_page.split(' ')[:-1]\n",
    "    is_appendix = elems[0] == 'Appendix'\n",
    "    section_number = \" \".join(elems[:2]) if is_appendix else elems[0]\n",
    "    title = \" \".join(elems[3:]) if is_appendix else \" \".join(elems[1:])\n",
    "    page = multi_line_section_map[section_number]-1 if section_number in multi_line_section_map else int(section[-2:].strip(' '))\n",
    "    return {\n",
    "        \"section_number\": section_number,\n",
    "        \"title\": title,\n",
    "        \"page\": page,\n",
    "    }\n",
    "\n",
    "\n",
    "def getSections(section_metas, pages):\n",
    "    full_sections = []\n",
    "    n_sections = len(section_metas)\n",
    "    n_pages = len(pages)\n",
    "\n",
    "    for i, meta in enumerate(section_metas):\n",
    "        start_page_idx = meta[\"page\"] - 1\n",
    "        if i + 1 < n_sections:\n",
    "            next_meta = section_metas[i + 1]\n",
    "            end_page_idx = next_meta[\"page\"] - 1\n",
    "        else:\n",
    "            next_meta = None\n",
    "            end_page_idx = n_pages - 1\n",
    "\n",
    "        start_page_text = pages[start_page_idx]\n",
    "        start_idx = start_page_text.find(meta['title'])\n",
    "\n",
    "        if next_meta is not None:\n",
    "            end_page_text = pages[end_page_idx]\n",
    "            end_idx = end_page_text.find(next_meta['title'])\n",
    "\n",
    "        else:\n",
    "            # Last section goes to end of last page\n",
    "            end_idx = len(pages[end_page_idx])\n",
    "\n",
    "        if start_page_idx == end_page_idx:\n",
    "            text_chunks = [pages[start_page_idx][start_idx:end_idx]]\n",
    "        else:\n",
    "            text_chunks = []\n",
    "            text_chunks.append(pages[start_page_idx][start_idx:])\n",
    "            for p in range(start_page_idx + 1, end_page_idx):\n",
    "                text_chunks.append(pages[p])\n",
    "\n",
    "            text_chunks.append(pages[end_page_idx][:end_idx])\n",
    "\n",
    "        if len(text_chunks) == 1 and not text_chunks[0]:\n",
    "            continue\n",
    "\n",
    "        section_text = \"\\n\\n\".join(text_chunks)\n",
    "            \n",
    "        full_sections.append({\n",
    "            **meta,\n",
    "            \"text\": section_text,\n",
    "        })\n",
    "\n",
    "    return full_sections\n",
    "\n",
    "def printSection(section_number):\n",
    "    section = sections.loc[sections.section_number == section_number].to_dict('records')[0]\n",
    "    print(f\"{section['section_number']} {section['title']} (page {section['page']+1})\\n\\n{section['text']}\")\n",
    "\n",
    "section_metas = [getSectionMeta(s) for s in table_of_contents if isSection(s)]\n",
    "sections = pd.DataFrame(getSections(section_metas, pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5337971d-d15c-417e-a20b-e86c3d2caaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_texts = sections['text']\n",
    "questions = pd.Series(['What do I do if I spilled something?', 'I got something in eye, what do I do?','What personal protective equipment do I need?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee374-e098-4ae8-9937-8e2e15474895",
   "metadata": {},
   "source": [
    "# TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "990688a4-d4a4-4649-80a5-0875af1078b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = pd.concat(\n",
    "    [section_texts, questions],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(all_texts)\n",
    "\n",
    "n_sections = len(section_texts)\n",
    "section_tfidf = tfidf_matrix[:n_sections]\n",
    "question_tfidf = tfidf_matrix[n_sections:] \n",
    "\n",
    "def rank_sections_tfidf(q_idx):\n",
    "    q_vec = question_tfidf[q_idx]\n",
    "    sims = cosine_similarity(q_vec, section_tfidf)[0]\n",
    "    ranked = np.argsort(-sims)\n",
    "    return ranked\n",
    "\n",
    "def top_n_sections_tfidf(q_idx, n_sections):\n",
    "    ranks = rank_sections_tfidf(q_idx)\n",
    "    return np.argsort(ranks)[:n_sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7209fdee-23f7-4671-b134-eacd495327df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55, 61, 62, 63, 47, 58, 57, 56, 59, 50])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_sections_tfidf(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adaedd-0a2a-42b9-999f-f8af4efe0f3e",
   "metadata": {},
   "source": [
    "# DistilBERT embedding baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "04d1cd1c-1f15-4cb5-8eac-b5c89e43b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def encode_texts(texts, max_length=256):\n",
    "    all_embs = []\n",
    "    batch_size = 8\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = distilbert(**tokens)\n",
    "        hidden = outputs.last_hidden_state\n",
    "\n",
    "        # Compute mean embedding\n",
    "        mask = tokens[\"attention_mask\"].unsqueeze(-1)\n",
    "        emb = (hidden * mask).sum(dim=1) / mask.sum(dim=1)\n",
    "        all_embs.append(emb.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8513fe37-b37b-4331-ad21-8cefab85d8cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 768), (3, 768))"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_texts = sections[\"text\"].tolist()\n",
    "question_texts = questions.tolist()\n",
    "\n",
    "section_embeddings = encode_texts(section_texts)\n",
    "question_embeddings = encode_texts(question_texts)\n",
    "\n",
    "section_embeddings.shape, question_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f6385881-b0b6-4a6b-9b2b-a9703cd9d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sections_embedding(q_idx):\n",
    "    q_vec = question_embeddings[q_idx:q_idx+1]        # shape (1, H)\n",
    "    sims = cosine_similarity(q_vec, section_embeddings)[0]  # (n_sections,)\n",
    "    ranked = np.argsort(-sims)                        # indices of sections_df, best first\n",
    "    return ranked\n",
    "\n",
    "def top_n_sections_embedding(q_idx, n_sections):\n",
    "    ranks = rank_sections_embedding(q_idx)\n",
    "    return np.argsort(ranks)[:n_sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2c7601b7-8bb0-49ec-a0e7-2c3aa47bec4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 68,  87,  49,  45,  78,  91,  88, 120,  59, 102])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_sections_embedding(0,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffaae6d-f7a1-415f-b654-673f3f363bb9",
   "metadata": {},
   "source": [
    "# Attention-Based Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a2b93bbd-f47a-4695-b645-6b5f71b0c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def attention_scores_for_question(question_text, section_texts, max_length=256, batch_size=8):\n",
    "    num_sections = len(section_texts)\n",
    "    num_layers = distilbert.config.num_hidden_layers\n",
    "    num_heads = distilbert.config.n_heads \n",
    "    \n",
    "    scores = np.zeros((num_layers, num_heads, num_sections), dtype=np.float32)\n",
    "    \n",
    "    for start in range(0, num_sections, batch_size):\n",
    "        end = min(start + batch_size, num_sections)\n",
    "        num_sections_in_batch = end - start\n",
    "        batch_sections = section_texts[start:end]\n",
    "        batch_question = [question_text] * num_sections_in_batch\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            batch_question,\n",
    "            batch_sections,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = distilbert(**tokens, output_attentions=True)\n",
    "        attentions = outputs.attentions\n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "\n",
    "        for i in range(num_sections_in_batch):\n",
    "            section_idx = start + i\n",
    "            \n",
    "            ids = input_ids[i]\n",
    "            sep_id = tokenizer.sep_token_id\n",
    "            sep_positions = (ids == sep_id).nonzero(as_tuple=False).flatten().tolist()\n",
    "\n",
    "            # should be of the form [CLS] question [SEP] section [SEP]\n",
    "            first_sep, second_sep = sep_positions[0], sep_positions[1]\n",
    "            q_idx = list(range(1, first_sep))\n",
    "            s_idx = list(range(first_sep + 1, second_sep))\n",
    "\n",
    "            for layer_idx, batch_layer_attentions in enumerate(attentions):\n",
    "                layer_attentions = batch_layer_attentions[i]\n",
    "                for head_idx in range(num_heads):\n",
    "                    head_attention = layer_attentions[head_idx]\n",
    "                    q2s_attention = head_attention[np.ix_(q_idx, s_idx)]\n",
    "                    scores[layer_idx, head_idx, section_idx] = q2s_attention.mean().item()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bcd42651-74fd-476f-ad84-09892dc9cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_sections_attention(q_idx):\n",
    "    q_text = questions.tolist()[q_idx]\n",
    "    sec_texts = sections[\"text\"].tolist()\n",
    "\n",
    "    scores = attention_scores_for_question(\n",
    "        q_text,\n",
    "        sec_texts,\n",
    "        max_length=256,\n",
    "        batch_size=8\n",
    "    )\n",
    "\n",
    "    ranked = np.argsort(-scores) # (layers, heads, ranks)\n",
    "    return ranked\n",
    "\n",
    "def top_n_sections_attention(q_idx, n_sections):\n",
    "    ranks = rank_sections_attention(q_idx)\n",
    "    return np.argsort(ranks)[:,:,:n_sections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "df81a611-0540-423d-8791-f9f3e4d6441c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 12, 5)\n",
      "[86 42 61 73 17]\n"
     ]
    }
   ],
   "source": [
    "x = top_n_sections_attention(1,5)\n",
    "\n",
    "print(x.shape)\n",
    "print(x[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a097f02-9f73-4273-9df0-21e552d3150f",
   "metadata": {},
   "source": [
    "# Decoding & Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a2579455-d3e3-4b5e-8ab7-f951d183d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createResults(top_n = 5):\n",
    "    num_questions = len(questions)\n",
    "    all_dfs = []\n",
    "    for q in range(num_questions):\n",
    "        attention_inds = top_n_sections_attention(q,top_n)\n",
    "        embedding_inds = top_n_sections_embedding(q,top_n)\n",
    "        tfidf_inds = top_n_sections_tfidf(q,top_n)\n",
    "        \n",
    "        embedding_sections = sections.iloc[embedding_inds]['section_number'].reset_index(drop=True)\n",
    "        tfidf_sections = sections.iloc[tfidf_inds]['section_number'].reset_index(drop=True)\n",
    "        results = {'question_ind':q,'rank':range(top_n),'tfidf': tfidf_sections, 'embedding':embedding_sections}\n",
    "        for l,layer in enumerate(attention_inds):\n",
    "            for h,head_inds in enumerate(layer):\n",
    "                results[f\"attention_{l}_{h}\"] = sections.iloc[head_inds]['section_number'].reset_index(drop=True)\n",
    "        all_dfs.append(pd.DataFrame(results))\n",
    "    return pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a57c1b56-ddfe-4df2-9d29-408031f1307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_ind</th>\n",
       "      <th>rank</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>embedding</th>\n",
       "      <th>attention_0_0</th>\n",
       "      <th>attention_0_1</th>\n",
       "      <th>attention_0_2</th>\n",
       "      <th>attention_0_3</th>\n",
       "      <th>attention_0_4</th>\n",
       "      <th>attention_0_5</th>\n",
       "      <th>...</th>\n",
       "      <th>attention_5_2</th>\n",
       "      <th>attention_5_3</th>\n",
       "      <th>attention_5_4</th>\n",
       "      <th>attention_5_5</th>\n",
       "      <th>attention_5_6</th>\n",
       "      <th>attention_5_7</th>\n",
       "      <th>attention_5_8</th>\n",
       "      <th>attention_5_9</th>\n",
       "      <th>attention_5_10</th>\n",
       "      <th>attention_5_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4.2</td>\n",
       "      <td>2.4.6.3</td>\n",
       "      <td>2.4.14.4</td>\n",
       "      <td>2.4.21.4</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>Appendix 5</td>\n",
       "      <td>Appendix 7</td>\n",
       "      <td>Appendix 11</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.6</td>\n",
       "      <td>2.4.2.2</td>\n",
       "      <td>2.4.11.1</td>\n",
       "      <td>2.4.6.3</td>\n",
       "      <td>2.4.8</td>\n",
       "      <td>2.4.3</td>\n",
       "      <td>2.4.13.1</td>\n",
       "      <td>2.4.11.1</td>\n",
       "      <td>2.4.12.1</td>\n",
       "      <td>2.4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>2.4.14.3</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.4.14</td>\n",
       "      <td>2.4.21.4</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.17</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.13.1</td>\n",
       "      <td>2.3.13.1</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.13</td>\n",
       "      <td>2.3.17</td>\n",
       "      <td>2.3.16</td>\n",
       "      <td>2.3.17</td>\n",
       "      <td>2.3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.3.19</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>2.4.20</td>\n",
       "      <td>2.3.22</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3.19</td>\n",
       "      <td>2.3.17.1</td>\n",
       "      <td>2.4.4.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4.2.1</td>\n",
       "      <td>2.3.17.1</td>\n",
       "      <td>2.4.5</td>\n",
       "      <td>2.4.2</td>\n",
       "      <td>2.3.22</td>\n",
       "      <td>2.4.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>2.3.16</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>Appendix 2</td>\n",
       "      <td>Appendix 10</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.21.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.21.2</td>\n",
       "      <td>2.4.18</td>\n",
       "      <td>2.4.21.7</td>\n",
       "      <td>2.4.21</td>\n",
       "      <td>2.4.19</td>\n",
       "      <td>2.4.17.2</td>\n",
       "      <td>2.4.14.5</td>\n",
       "      <td>2.4.21.4</td>\n",
       "      <td>2.4.21.6</td>\n",
       "      <td>2.4.21.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.3.17.1</td>\n",
       "      <td>2.4.12.1</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.3.9</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>1.3.1</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3.12.2</td>\n",
       "      <td>Appendix 2</td>\n",
       "      <td>2.4.14.2</td>\n",
       "      <td>2.4.18</td>\n",
       "      <td>2.4.21.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.4.21</td>\n",
       "      <td>Appendix 7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.6.4</td>\n",
       "      <td>2.4.4.1</td>\n",
       "      <td>2.4.7</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.6.2</td>\n",
       "      <td>2.3.20</td>\n",
       "      <td>2.4.14.1</td>\n",
       "      <td>2.4.12.2</td>\n",
       "      <td>2.4.12.1</td>\n",
       "      <td>2.4.6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4.17.1</td>\n",
       "      <td>2.4.7</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.13.1</td>\n",
       "      <td>2.4.21.5</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.13.1</td>\n",
       "      <td>2.3.13.1</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.12.2</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.16</td>\n",
       "      <td>2.3.14</td>\n",
       "      <td>2.3.13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4.14.5</td>\n",
       "      <td>2.4.12.1</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>2.4.4.1</td>\n",
       "      <td>2.3.12.2</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.2</td>\n",
       "      <td>2.3.19</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2.4.2.2</td>\n",
       "      <td>2.3.17</td>\n",
       "      <td>2.4.6</td>\n",
       "      <td>2.4.2.2</td>\n",
       "      <td>2.4.3</td>\n",
       "      <td>2.4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4.2</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.2.2</td>\n",
       "      <td>2.4.21.4</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.21.3</td>\n",
       "      <td>2.4.19</td>\n",
       "      <td>2.4.21.1</td>\n",
       "      <td>2.4.21.3</td>\n",
       "      <td>2.4.21</td>\n",
       "      <td>2.4.17.2</td>\n",
       "      <td>2.4.13.1</td>\n",
       "      <td>2.4.21.5</td>\n",
       "      <td>2.4.21.5</td>\n",
       "      <td>2.4.21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4.17</td>\n",
       "      <td>2.4.14.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.3.9</td>\n",
       "      <td>2.3.20</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.3.2</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>1.2.2</td>\n",
       "      <td>1.1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.4.4</td>\n",
       "      <td>2.4.21.7</td>\n",
       "      <td>2.4.14.5</td>\n",
       "      <td>2.4.14.1</td>\n",
       "      <td>2.4.12.2</td>\n",
       "      <td>2.4.21.3</td>\n",
       "      <td>Appendix 1</td>\n",
       "      <td>Appendix 3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2.4.12</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>2.4.4.1</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2.4.11.2</td>\n",
       "      <td>2.4.6.3</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2.4.6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4.15</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.4.18</td>\n",
       "      <td>Appendix 15</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>2.3.13.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3.16</td>\n",
       "      <td>2.3.13</td>\n",
       "      <td>2.3.14</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.13.1</td>\n",
       "      <td>2.3.12</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.14</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.3.13.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.4.14</td>\n",
       "      <td>2.4.4.2</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>2.3.4</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3.17</td>\n",
       "      <td>2.4.4</td>\n",
       "      <td>2.3.21</td>\n",
       "      <td>2.4.1</td>\n",
       "      <td>2.3.15</td>\n",
       "      <td>2.4.3</td>\n",
       "      <td>2.4.2</td>\n",
       "      <td>2.3.17</td>\n",
       "      <td>2.3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4.4.4</td>\n",
       "      <td>2.4.4.3</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.2.1</td>\n",
       "      <td>Appendix 2</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>2.4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4.17</td>\n",
       "      <td>2.4.18</td>\n",
       "      <td>2.4.17.1</td>\n",
       "      <td>2.4.17.1</td>\n",
       "      <td>2.4.16</td>\n",
       "      <td>2.4.17.1</td>\n",
       "      <td>2.4.14.4</td>\n",
       "      <td>2.4.14.5</td>\n",
       "      <td>2.4.17.2</td>\n",
       "      <td>2.4.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4.3</td>\n",
       "      <td>2.4.14.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>1.3.2</td>\n",
       "      <td>2.3.12.2</td>\n",
       "      <td>2.2.2</td>\n",
       "      <td>2.2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3.3</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>1.3.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows Ã— 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   question_ind  rank     tfidf   embedding attention_0_0 attention_0_1  \\\n",
       "0             0     0     2.4.2     2.4.6.3      2.4.14.4      2.4.21.4   \n",
       "1             0     1   2.4.4.2    2.4.14.3      2.3.13.2      2.3.13.2   \n",
       "2             0     2   2.4.4.3      2.3.19       2.4.4.2       2.4.4.4   \n",
       "3             0     3   2.4.4.4      2.3.16        2.4.10        2.4.10   \n",
       "4             0     4  2.3.17.1    2.4.12.1         2.2.2         2.2.2   \n",
       "0             1     0  2.3.12.2  Appendix 2      2.4.14.2        2.4.18   \n",
       "1             1     1  2.4.17.1       2.4.7      2.3.13.2      2.3.13.2   \n",
       "2             1     2  2.4.14.5    2.4.12.1       2.4.4.2       2.4.4.4   \n",
       "3             1     3     2.4.2       2.4.1        2.4.10        2.4.10   \n",
       "4             1     4    2.4.17    2.4.14.2         2.2.2         2.2.2   \n",
       "0             2     0     2.4.4    2.4.21.7      2.4.14.5      2.4.14.1   \n",
       "1             2     1       2.3      2.4.15      2.3.13.2      2.3.13.2   \n",
       "2             2     2   2.4.4.3      2.4.14       2.4.4.2       2.4.4.4   \n",
       "3             2     3   2.4.4.4     2.4.4.3        2.4.10        2.4.10   \n",
       "4             2     4     2.4.3    2.4.14.2         2.2.2         2.2.2   \n",
       "\n",
       "  attention_0_2 attention_0_3 attention_0_4 attention_0_5  ... attention_5_2  \\\n",
       "0       2.4.4.2    Appendix 5    Appendix 7   Appendix 11  ...         2.4.6   \n",
       "1        2.4.14      2.4.21.4      2.3.13.2        2.3.17  ...        2.3.15   \n",
       "2        2.4.20        2.3.22       2.4.4.3         2.4.6  ...        2.3.19   \n",
       "3    Appendix 2   Appendix 10        2.4.10      2.4.21.2  ...      2.4.21.2   \n",
       "4         2.2.2         2.3.9         2.2.2         2.3.1  ...         1.2.1   \n",
       "0      2.4.21.1           2.5        2.4.21    Appendix 7  ...       2.4.6.4   \n",
       "1      2.3.13.1      2.4.21.5      2.3.13.2        2.3.16  ...        2.3.15   \n",
       "2       2.4.4.1      2.3.12.2       2.4.4.2       2.4.4.4  ...         2.4.2   \n",
       "3       2.4.2.2      2.4.21.4        2.4.10      2.4.14.1  ...      2.4.21.3   \n",
       "4         2.3.9        2.3.20         2.2.2         2.3.1  ...           1.3   \n",
       "0      2.4.12.2      2.4.21.3    Appendix 1    Appendix 3  ...       2.4.4.3   \n",
       "1        2.4.18   Appendix 15      2.3.13.2      2.3.13.2  ...        2.3.16   \n",
       "2         2.3.4        2.3.15       2.4.4.3       2.4.4.4  ...           2.4   \n",
       "3       2.4.2.1    Appendix 2        2.4.10        2.4.10  ...        2.4.17   \n",
       "4         1.3.2      2.3.12.2         2.2.2         2.2.3  ...         1.3.3   \n",
       "\n",
       "  attention_5_3 attention_5_4 attention_5_5 attention_5_6 attention_5_7  \\\n",
       "0       2.4.2.2      2.4.11.1       2.4.6.3         2.4.8         2.4.3   \n",
       "1      2.3.13.1      2.3.13.1        2.3.15      2.3.13.2        2.3.13   \n",
       "2      2.3.17.1       2.4.4.1           2.4       2.4.2.1      2.3.17.1   \n",
       "3        2.4.18      2.4.21.7        2.4.21        2.4.19      2.4.17.2   \n",
       "4         1.1.2           2.1           1.2           1.3         1.1.2   \n",
       "0       2.4.4.1         2.4.7        2.4.10       2.4.6.2        2.3.20   \n",
       "1      2.3.13.1      2.3.13.1        2.3.15      2.3.13.2      2.3.12.2   \n",
       "2        2.3.19       2.4.4.3         2.4.1       2.4.2.2        2.3.17   \n",
       "3        2.4.19      2.4.21.1      2.4.21.3        2.4.21      2.4.17.2   \n",
       "4       1.1.1.1           2.1           1.3         1.3.2       1.1.1.1   \n",
       "0         2.4.1        2.4.12       2.4.4.2       2.4.4.1         2.4.1   \n",
       "1        2.3.13        2.3.14        2.3.15      2.3.13.1        2.3.12   \n",
       "2        2.3.17         2.4.4        2.3.21         2.4.1        2.3.15   \n",
       "3        2.4.18      2.4.17.1      2.4.17.1        2.4.16      2.4.17.1   \n",
       "4         1.1.3           2.1         1.2.1           2.1         1.1.2   \n",
       "\n",
       "  attention_5_8 attention_5_9 attention_5_10 attention_5_11  \n",
       "0      2.4.13.1      2.4.11.1       2.4.12.1         2.4.13  \n",
       "1        2.3.17        2.3.16         2.3.17         2.3.15  \n",
       "2         2.4.5         2.4.2         2.3.22        2.4.2.1  \n",
       "3      2.4.14.5      2.4.21.4       2.4.21.6       2.4.21.3  \n",
       "4         1.3.1         1.1.3            1.2          1.1.3  \n",
       "0      2.4.14.1      2.4.12.2       2.4.12.1        2.4.6.3  \n",
       "1        2.3.15        2.3.16         2.3.14       2.3.13.1  \n",
       "2         2.4.6       2.4.2.2          2.4.3          2.4.1  \n",
       "3      2.4.13.1      2.4.21.5       2.4.21.5       2.4.21.4  \n",
       "4           1.2         1.1.3          1.2.2          1.1.3  \n",
       "0      2.4.11.2       2.4.6.3          2.4.1        2.4.6.2  \n",
       "1        2.3.15        2.3.14         2.3.15       2.3.13.2  \n",
       "2         2.4.3         2.4.2         2.3.17         2.3.22  \n",
       "3      2.4.14.4      2.4.14.5       2.4.17.2         2.4.18  \n",
       "4         1.3.3           1.2          1.1.3            1.2  \n",
       "\n",
       "[15 rows x 76 columns]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = createResults()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880e3e6a-895f-440a-be09-440a2dca5a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
