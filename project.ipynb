{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748cb922-37aa-42c8-813d-e025f8746e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch scikit-learn pandas IProgress\n",
    "# !pip install pdfplumber\n",
    "# !pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced923ad-de95-41ec-9216-a2c0884fae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from docx import Document\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import AutoTokenizer, DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417b6922-2732-46f1-b230-b430e7418690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/broccoloni/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "distilbert = DistilBertModel.from_pretrained(model_name)\n",
    "distilbert.to(device)\n",
    "distilbert.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdce09e-552f-496b-8b91-45ae3ca54eb6",
   "metadata": {},
   "source": [
    "# Convert PDF to text and extract sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c467af0-a166-4cbd-acac-5698ab367070",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"RSM.pdf\"\n",
    "\n",
    "pages = []\n",
    "\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    for page_num, page in enumerate(pdf.pages):\n",
    "        text = page.extract_text()\n",
    "        if text is None:\n",
    "            text = \"\"\n",
    "        pages.append(text)\n",
    "\n",
    "full_text = \"\\n\\n\".join(pages)\n",
    "table_of_contents = full_text[3250:20000].split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaea942a-a622-4755-8727-bb81733a7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isSection(line):\n",
    "    elems = line.split(' ')\n",
    "    if not line or len(elems) == 0:\n",
    "        return False\n",
    "    if elems[0][0].isnumeric():\n",
    "        return True\n",
    "    elif elems[0] == 'Appendix':\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def getSectionMeta(section):\n",
    "    multi_line_section_map = {\n",
    "        '2.2.3': 17,\n",
    "        '2.3.4.1': 22,\n",
    "        '2.3.6': 22,\n",
    "        '2.4.6': 35,\n",
    "        '2.4.14.4': 54,\n",
    "        'Appendix 4': 71,\n",
    "    }\n",
    "    \n",
    "    removed_page = section[:-2]\n",
    "    elems = removed_page.split(' ')[:-1]\n",
    "    is_appendix = elems[0] == 'Appendix'\n",
    "    section_number = \" \".join(elems[:2]) if is_appendix else elems[0]\n",
    "    title = \" \".join(elems[3:]) if is_appendix else \" \".join(elems[1:])\n",
    "    page = multi_line_section_map[section_number]-1 if section_number in multi_line_section_map else int(section[-2:].strip(' '))\n",
    "    return {\n",
    "        \"section_number\": section_number.upper(),\n",
    "        \"title\": title,\n",
    "        \"page\": page,\n",
    "    }\n",
    "\n",
    "\n",
    "def getSections(section_metas, pages):\n",
    "    full_sections = []\n",
    "    n_sections = len(section_metas)\n",
    "    n_pages = len(pages)\n",
    "\n",
    "    for i, meta in enumerate(section_metas):\n",
    "        start_page_idx = meta[\"page\"] - 1\n",
    "        if i + 1 < n_sections:\n",
    "            next_meta = section_metas[i + 1]\n",
    "            end_page_idx = next_meta[\"page\"] - 1\n",
    "        else:\n",
    "            next_meta = None\n",
    "            end_page_idx = n_pages - 1\n",
    "\n",
    "        start_page_text = pages[start_page_idx]\n",
    "        start_idx = start_page_text.find(meta['section_number'])\n",
    "        \n",
    "        if next_meta is not None:\n",
    "            end_page_text = pages[end_page_idx]\n",
    "            end_idx = end_page_text.find(next_meta['section_number'])\n",
    "\n",
    "        else:\n",
    "            # Last section goes to end of last page\n",
    "            end_idx = len(pages[n_pages-1])\n",
    "\n",
    "        if start_page_idx == end_page_idx:\n",
    "            text_chunks = [pages[start_page_idx][start_idx:end_idx]]\n",
    "        else:\n",
    "            text_chunks = []\n",
    "            text_chunks.append(pages[start_page_idx][start_idx:])\n",
    "            for p in range(start_page_idx + 1, end_page_idx):\n",
    "                text_chunks.append(pages[p])\n",
    "\n",
    "            text_chunks.append(pages[end_page_idx][:end_idx])\n",
    "\n",
    "        if len(text_chunks) == 1 and not text_chunks[0]:\n",
    "            continue\n",
    "\n",
    "        section_text = \"\\n\\n\".join(text_chunks)\n",
    "\n",
    "        # Skip sections that are just the title (+space +newline char)\n",
    "        if len(section_text) <= len(meta['section_number'])+len(meta['title'])+2:\n",
    "            continue\n",
    "        \n",
    "        full_sections.append({\n",
    "            **meta,\n",
    "            \"text\": section_text,\n",
    "        })\n",
    "\n",
    "    return full_sections\n",
    "\n",
    "def printSection(section_number):\n",
    "    section = sections.loc[sections.section_number == section_number].to_dict('records')[0]\n",
    "    print(f\"{section['section_number']} {section['title']} (page {section['page']+1})\\n\\n{section['text']}\")\n",
    "\n",
    "section_metas = [getSectionMeta(s) for s in table_of_contents if isSection(s)]\n",
    "sections = pd.DataFrame(getSections(section_metas, pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1fbaaf1-7a50-49d0-8073-e9f6d6c1e2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters per section:\t\tmin 196\tmax 15603\tmean 1551.63\tstd 1928.66\n",
      "Characters per section:\t\tmin 31\tmax 2475\tmean 245.23\tstd 307.98\n"
     ]
    }
   ],
   "source": [
    "chars = sections.text.apply(lambda x: len(x))\n",
    "print(f\"Characters per section:\\t\\tmin {chars.min()}\\tmax {chars.max()}\\tmean {chars.mean():.2f}\\tstd {chars.std():.2f}\")\n",
    "\n",
    "words = sections.text.apply(lambda x: len(x.replace('\\n',' ').split(' ')))\n",
    "print(f\"Characters per section:\\t\\tmin {words.min()}\\tmax {words.max()}\\tmean {words.mean():.2f}\\tstd {words.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf52573-9ff4-4bf3-bd13-bf81d68e88cf",
   "metadata": {},
   "source": [
    "# Convert Questions to pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5337971d-d15c-417e-a20b-e86c3d2caaa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the non-fixed radiation contamination ...</td>\n",
       "      <td>[2.4.6.2, 2.4.6.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What procedures should be followed if the non-...</td>\n",
       "      <td>[2.4.6.2, 2.4.6.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When should the wipe tests be done after using...</td>\n",
       "      <td>[2.4.6.1, 2.3.6, 2.4.14.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When is leak testing of sealed sources or devi...</td>\n",
       "      <td>[2.4.8, 2.3.8, 2.4.11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the schedule for leak testing the seal...</td>\n",
       "      <td>[2.4.8, 2.3.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the leakage limit for sealed sources o...</td>\n",
       "      <td>[2.4.8, 2.3.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What happens if the sealed source leakage limi...</td>\n",
       "      <td>[2.4.8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the annual whole body dose limit for N...</td>\n",
       "      <td>[2.4.4.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is the annual dose limit in mSv for pregn...</td>\n",
       "      <td>[2.4.4.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the dosimetry requirements at the Uni...</td>\n",
       "      <td>[2.4.4.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>If I am working with less than 50 MBq of P-32,...</td>\n",
       "      <td>[2.4.4.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>What is the procedure to order a dosimeter at ...</td>\n",
       "      <td>[2.4.4.2, Appendix 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What is the action level at the University of ...</td>\n",
       "      <td>[2.4.5, Appendix 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What happens if action level is reached?</td>\n",
       "      <td>[2.3.5, 2.4.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the non-fixed contamination limit for ...</td>\n",
       "      <td>[2.4.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What are the procedures for decommissioning a ...</td>\n",
       "      <td>[2.4.15, 2.3.15]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Who is classified as a Nuclear Energy worker a...</td>\n",
       "      <td>[2.3.2.1, 2.4.2.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>What are the notification requirements for a N...</td>\n",
       "      <td>[2.4.2.2, 2.3.2.2, Appendix 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Where can I find a copy of the Nuclear Energy ...</td>\n",
       "      <td>[Appendix 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>As a Nuclear Energy Worker, how often should I...</td>\n",
       "      <td>[2.4.2.2, Appendix 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What are the training requirements for users w...</td>\n",
       "      <td>[2.3.3, 2.4.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>What is the list of topics that are covered in...</td>\n",
       "      <td>[2.3.3.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What is the minimum passing mark for the radia...</td>\n",
       "      <td>[2.4.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What happens if a sealed sources goes missing?</td>\n",
       "      <td>[2.4.9, 2.3.9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>How do I calculate my detector’s efficiency?</td>\n",
       "      <td>[2.4.6.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What steps should be followed before the use o...</td>\n",
       "      <td>[2.4.6.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How do I calculate my contamination reading in...</td>\n",
       "      <td>[Appendix 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>How do I perform contamination monitoring for ...</td>\n",
       "      <td>[2.4.6.2, 2.3.6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>What is the policy for retention of records pe...</td>\n",
       "      <td>[2.3.16, 2.4.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>What type of records are required to be retain...</td>\n",
       "      <td>[2.4.23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>What are the procedures that an RSO should fol...</td>\n",
       "      <td>[2.4.23, 2.4.16, 2.3.16]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>What are the retention periods for different t...</td>\n",
       "      <td>[2.4.23, 2.3.22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>What is the policy pertaining to declaring dor...</td>\n",
       "      <td>[2.4.21.4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>How often should each lab containing unsealed ...</td>\n",
       "      <td>[2.4.19, 2.3.19]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>What is the policy on administering radionucli...</td>\n",
       "      <td>[2.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How should we get rid of both short lived or l...</td>\n",
       "      <td>[2.5, 2.4.13.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What are the procedures for handling minor and...</td>\n",
       "      <td>[2.4.14.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What is the time frame for notifying CNSC in c...</td>\n",
       "      <td>[2.4.16, 2.4.14.3, 2.4.22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>What are the procedures for purchasing new rad...</td>\n",
       "      <td>[2.4.12.1, 2.3.12.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What is the code required for purchasing radio...</td>\n",
       "      <td>[2.4.12.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>How is the inventory of nuclear substances to ...</td>\n",
       "      <td>[2.4.12.2, 2.3.12.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Where can I find inventory forms?</td>\n",
       "      <td>[Appendix 6 and 7, 2.4.12.2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>How many different types of inventory forms ar...</td>\n",
       "      <td>[2.4.12.2, Appendix 6 and 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>What is the policy on storage of radioactive m...</td>\n",
       "      <td>[2.4.12.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Where can I find signage and postings includin...</td>\n",
       "      <td>[Appendix 13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>What are the signage requirements for labeling...</td>\n",
       "      <td>[2.3.17.1, 2.4.13.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>What information should be on the radioactive ...</td>\n",
       "      <td>[2.3.17, 2.4.13.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>At what dose rate is radioactive signage requi...</td>\n",
       "      <td>[2.3.17, 2.4.17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Where can I find the contact information of CN...</td>\n",
       "      <td>[2.3.14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>What procedures should I follow to submit radi...</td>\n",
       "      <td>[2.4.13.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Where can I find the radioactive waste disposa...</td>\n",
       "      <td>[2.4.13.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>What are the roles and responsibilities of an ...</td>\n",
       "      <td>[1.3.4.1, 2.2.1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>What are the roles and responsibilities of aut...</td>\n",
       "      <td>[2.2.3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>What are the roles and responsibilities of the...</td>\n",
       "      <td>[2.2.2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   What is the non-fixed radiation contamination ...   \n",
       "1   What procedures should be followed if the non-...   \n",
       "2   When should the wipe tests be done after using...   \n",
       "3   When is leak testing of sealed sources or devi...   \n",
       "4   What is the schedule for leak testing the seal...   \n",
       "5   What is the leakage limit for sealed sources o...   \n",
       "6   What happens if the sealed source leakage limi...   \n",
       "7   What is the annual whole body dose limit for N...   \n",
       "8   What is the annual dose limit in mSv for pregn...   \n",
       "9   What are the dosimetry requirements at the Uni...   \n",
       "10  If I am working with less than 50 MBq of P-32,...   \n",
       "11  What is the procedure to order a dosimeter at ...   \n",
       "12  What is the action level at the University of ...   \n",
       "13           What happens if action level is reached?   \n",
       "14  What is the non-fixed contamination limit for ...   \n",
       "15  What are the procedures for decommissioning a ...   \n",
       "16  Who is classified as a Nuclear Energy worker a...   \n",
       "17  What are the notification requirements for a N...   \n",
       "18  Where can I find a copy of the Nuclear Energy ...   \n",
       "19  As a Nuclear Energy Worker, how often should I...   \n",
       "20  What are the training requirements for users w...   \n",
       "21  What is the list of topics that are covered in...   \n",
       "22  What is the minimum passing mark for the radia...   \n",
       "23     What happens if a sealed sources goes missing?   \n",
       "24       How do I calculate my detector’s efficiency?   \n",
       "25  What steps should be followed before the use o...   \n",
       "26  How do I calculate my contamination reading in...   \n",
       "27  How do I perform contamination monitoring for ...   \n",
       "28  What is the policy for retention of records pe...   \n",
       "29  What type of records are required to be retain...   \n",
       "30  What are the procedures that an RSO should fol...   \n",
       "31  What are the retention periods for different t...   \n",
       "32  What is the policy pertaining to declaring dor...   \n",
       "33  How often should each lab containing unsealed ...   \n",
       "34  What is the policy on administering radionucli...   \n",
       "35  How should we get rid of both short lived or l...   \n",
       "36  What are the procedures for handling minor and...   \n",
       "37  What is the time frame for notifying CNSC in c...   \n",
       "38  What are the procedures for purchasing new rad...   \n",
       "39  What is the code required for purchasing radio...   \n",
       "40  How is the inventory of nuclear substances to ...   \n",
       "41                  Where can I find inventory forms?   \n",
       "42  How many different types of inventory forms ar...   \n",
       "43  What is the policy on storage of radioactive m...   \n",
       "44  Where can I find signage and postings includin...   \n",
       "45  What are the signage requirements for labeling...   \n",
       "46  What information should be on the radioactive ...   \n",
       "47  At what dose rate is radioactive signage requi...   \n",
       "48  Where can I find the contact information of CN...   \n",
       "49  What procedures should I follow to submit radi...   \n",
       "50  Where can I find the radioactive waste disposa...   \n",
       "51  What are the roles and responsibilities of an ...   \n",
       "52  What are the roles and responsibilities of aut...   \n",
       "53  What are the roles and responsibilities of the...   \n",
       "\n",
       "                            section  \n",
       "0                [2.4.6.2, 2.4.6.4]  \n",
       "1                [2.4.6.2, 2.4.6.4]  \n",
       "2        [2.4.6.1, 2.3.6, 2.4.14.1]  \n",
       "3            [2.4.8, 2.3.8, 2.4.11]  \n",
       "4                    [2.4.8, 2.3.8]  \n",
       "5                    [2.4.8, 2.3.8]  \n",
       "6                           [2.4.8]  \n",
       "7                         [2.4.4.1]  \n",
       "8                         [2.4.4.1]  \n",
       "9                         [2.4.4.2]  \n",
       "10                        [2.4.4.2]  \n",
       "11            [2.4.4.2, Appendix 8]  \n",
       "12             [2.4.5, Appendix 14]  \n",
       "13                   [2.3.5, 2.4.5]  \n",
       "14                         [2.4.15]  \n",
       "15                 [2.4.15, 2.3.15]  \n",
       "16               [2.3.2.1, 2.4.2.1]  \n",
       "17  [2.4.2.2, 2.3.2.2, Appendix 14]  \n",
       "18                    [Appendix 14]  \n",
       "19           [2.4.2.2, Appendix 14]  \n",
       "20                   [2.3.3, 2.4.3]  \n",
       "21                        [2.3.3.1]  \n",
       "22                          [2.4.3]  \n",
       "23                   [2.4.9, 2.3.9]  \n",
       "24                        [2.4.6.4]  \n",
       "25                        [2.4.6.3]  \n",
       "26                     [Appendix 5]  \n",
       "27                 [2.4.6.2, 2.3.6]  \n",
       "28                 [2.3.16, 2.4.16]  \n",
       "29                         [2.4.23]  \n",
       "30         [2.4.23, 2.4.16, 2.3.16]  \n",
       "31                 [2.4.23, 2.3.22]  \n",
       "32                       [2.4.21.4]  \n",
       "33                 [2.4.19, 2.3.19]  \n",
       "34                            [2.5]  \n",
       "35                  [2.5, 2.4.13.1]  \n",
       "36                       [2.4.14.1]  \n",
       "37       [2.4.16, 2.4.14.3, 2.4.22]  \n",
       "38             [2.4.12.1, 2.3.12.1]  \n",
       "39                       [2.4.12.1]  \n",
       "40             [2.4.12.2, 2.3.12.2]  \n",
       "41     [Appendix 6 and 7, 2.4.12.2]  \n",
       "42     [2.4.12.2, Appendix 6 and 7]  \n",
       "43                       [2.4.12.3]  \n",
       "44                    [Appendix 13]  \n",
       "45             [2.3.17.1, 2.4.13.1]  \n",
       "46               [2.3.17, 2.4.13.1]  \n",
       "47                 [2.3.17, 2.4.17]  \n",
       "48                         [2.3.14]  \n",
       "49                       [2.4.13.1]  \n",
       "50                       [2.4.13.1]  \n",
       "51                 [1.3.4.1, 2.2.1]  \n",
       "52                          [2.2.3]  \n",
       "53                          [2.2.2]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = Document(\"RSM_Questions.docx\")\n",
    "\n",
    "questions = pd.DataFrame(columns=['question','section'])\n",
    "text = [p.text.strip(' ') for p in doc.paragraphs if len(p.text) > 1]\n",
    "t = 0\n",
    "\n",
    "cur_question = ''\n",
    "cur_labels = []\n",
    "while t < len(text):\n",
    "    components = text[t].split(' ')\n",
    "\n",
    "    # labels\n",
    "    if components[0].lower() == 'section':\n",
    "        cur_labels.append(components[-1])\n",
    "    elif components[0].lower() == 'appendix':\n",
    "        cur_labels.append(text[t])\n",
    "\n",
    "    # question\n",
    "    else:\n",
    "        # Store prev question\n",
    "        if cur_question:\n",
    "            questions.loc[len(questions),:] = [cur_question, cur_labels]\n",
    "\n",
    "        # Reset \n",
    "        cur_question = text[t]\n",
    "        cur_labels = []\n",
    "\n",
    "    t += 1\n",
    "\n",
    "questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08aee374-e098-4ae8-9937-8e2e15474895",
   "metadata": {},
   "source": [
    "# TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "990688a4-d4a4-4649-80a5-0875af1078b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = pd.concat(\n",
    "    [sections.text, questions.question],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(all_texts)\n",
    "\n",
    "n_sections = len(sections.text)\n",
    "section_tfidf = tfidf_matrix[:n_sections]\n",
    "question_tfidf = tfidf_matrix[n_sections:] \n",
    "\n",
    "def get_scores_tfidf(q_idx):\n",
    "    q_vec = question_tfidf[q_idx]\n",
    "    scores = cosine_similarity(q_vec, section_tfidf)[0]\n",
    "    return scores\n",
    "\n",
    "def rank_sections_tfidf(q_idx):\n",
    "    q_vec = question_tfidf[q_idx]\n",
    "    sims = cosine_similarity(q_vec, section_tfidf)[0]\n",
    "    ranked = np.argsort(-sims)\n",
    "    return ranked\n",
    "\n",
    "def top_n_sections_tfidf(q_idx, n_sections):\n",
    "    ranks = rank_sections_tfidf(q_idx)\n",
    "    return ranks[:n_sections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12adaedd-0a2a-42b9-999f-f8af4efe0f3e",
   "metadata": {},
   "source": [
    "# DistilBERT embedding baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04d1cd1c-1f15-4cb5-8eac-b5c89e43b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def encode_texts(texts, max_length=256):\n",
    "    all_embs = []\n",
    "    batch_size = 8\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        tokens = tokenizer(\n",
    "            batch,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = distilbert(**tokens)\n",
    "        hidden = outputs.last_hidden_state\n",
    "\n",
    "        # Compute mean embedding\n",
    "        mask = tokens[\"attention_mask\"].unsqueeze(-1)\n",
    "        emb = (hidden * mask).sum(dim=1) / mask.sum(dim=1)\n",
    "        all_embs.append(emb.cpu().numpy())\n",
    "\n",
    "    return np.vstack(all_embs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6385881-b0b6-4a6b-9b2b-a9703cd9d2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_embedding(q_idx):\n",
    "    section_texts = sections.text.tolist()\n",
    "    question_texts = questions.question.tolist()\n",
    "    section_embeddings = encode_texts(section_texts)\n",
    "    question_embeddings = encode_texts(question_texts)\n",
    "    q_vec = question_embeddings[q_idx:q_idx+1]\n",
    "    scores = cosine_similarity(q_vec, section_embeddings)[0]    \n",
    "    return scores\n",
    "\n",
    "def rank_sections_embedding(q_idx):\n",
    "    section_texts = sections.text.tolist()\n",
    "    question_texts = questions.question.tolist()\n",
    "    section_embeddings = encode_texts(section_texts)\n",
    "    question_embeddings = encode_texts(question_texts)\n",
    "    q_vec = question_embeddings[q_idx:q_idx+1]\n",
    "    sims = cosine_similarity(q_vec, section_embeddings)[0]\n",
    "    ranked = np.argsort(-sims)\n",
    "    return ranked\n",
    "\n",
    "def top_n_sections_embedding(q_idx, n_sections):\n",
    "    ranks = rank_sections_embedding(q_idx)\n",
    "    return ranks[:n_sections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffaae6d-f7a1-415f-b654-673f3f363bb9",
   "metadata": {},
   "source": [
    "# Attention-Based Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b93bbd-f47a-4695-b645-6b5f71b0c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def attention_scores_for_question(question_text, section_texts, max_length=256, batch_size=8, return_attention=False):\n",
    "    num_sections = len(section_texts)\n",
    "    num_layers = distilbert.config.num_hidden_layers\n",
    "    num_heads = distilbert.config.n_heads \n",
    "\n",
    "    if not return_attention:\n",
    "        scores = np.zeros((num_layers, num_heads, num_sections), dtype=np.float32)\n",
    "    else:\n",
    "        q2s_blocks = [\n",
    "            [[None for _ in range(num_sections)] for _ in range(num_heads)]\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        s2q_blocks = [\n",
    "            [[None for _ in range(num_sections)] for _ in range(num_heads)]\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        q2q_blocks = [\n",
    "            [[None for _ in range(num_sections)] for _ in range(num_heads)]\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        s2s_blocks = [\n",
    "            [[None for _ in range(num_sections)] for _ in range(num_heads)]\n",
    "            for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "    for start in range(0, num_sections, batch_size):\n",
    "        end = min(start + batch_size, num_sections)\n",
    "        num_sections_in_batch = end - start\n",
    "        batch_sections = section_texts[start:end]\n",
    "        batch_question = [question_text] * num_sections_in_batch\n",
    "\n",
    "        tokens = tokenizer(\n",
    "            batch_question,\n",
    "            batch_sections,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = distilbert(**tokens, output_attentions=True)\n",
    "        attentions = outputs.attentions\n",
    "        input_ids = tokens[\"input_ids\"]\n",
    "\n",
    "        for i in range(num_sections_in_batch):\n",
    "            section_idx = start + i\n",
    "            \n",
    "            ids = input_ids[i]\n",
    "            sep_id = tokenizer.sep_token_id\n",
    "            sep_positions = (ids == sep_id).nonzero(as_tuple=False).flatten().tolist()\n",
    "\n",
    "            # should be of the form [CLS] question [SEP] section [SEP]\n",
    "            first_sep, second_sep = sep_positions[0], sep_positions[1]\n",
    "            q_idx = list(range(1, first_sep))\n",
    "            s_idx = list(range(first_sep + 1, second_sep))\n",
    "\n",
    "            for layer_idx, batch_layer_attentions in enumerate(attentions):\n",
    "                layer_attentions = batch_layer_attentions[i]\n",
    "                for head_idx in range(num_heads):\n",
    "                    head_attention = layer_attentions[head_idx]\n",
    "\n",
    "                    q2s = head_attention[np.ix_(q_idx, s_idx)]\n",
    "                    s2q = head_attention[np.ix_(s_idx, q_idx)]\n",
    "\n",
    "                    if not return_attention:\n",
    "                        val = q2s.mean().item() + s2q.mean().item()\n",
    "                        scores[layer_idx, head_idx, section_idx] = val\n",
    "                    else:\n",
    "                        q2q = head_attention[np.ix_(q_idx, q_idx)]\n",
    "                        s2s = head_attention[np.ix_(s_idx, s_idx)]\n",
    "\n",
    "                        q2s_blocks[layer_idx][head_idx][section_idx] = q2s.cpu().numpy()\n",
    "                        s2q_blocks[layer_idx][head_idx][section_idx] = s2q.cpu().numpy()\n",
    "                        q2q_blocks[layer_idx][head_idx][section_idx] = q2q.cpu().numpy()\n",
    "                        s2s_blocks[layer_idx][head_idx][section_idx] = s2s.cpu().numpy()\n",
    "\n",
    "    if not return_attention:\n",
    "        return scores\n",
    "    else:\n",
    "        return q2s_blocks, s2q_blocks, q2q_blocks, s2s_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35600046-5332-4aae-9191-7eb812caebc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 54/54\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "def collect_attention_blocks_stream(questions, sections, path=\"attention_blocks_stream.pkl\",\n",
    "                                    max_length=256, batch_size=8):\n",
    "    sec_texts = sections[\"text\"].tolist()\n",
    "    with open(path, \"wb\") as f:\n",
    "        for q_idx, row in questions.reset_index().iterrows():\n",
    "            print(f\"Question {q_idx+1}/{len(questions)}\", end=\"\\r\")\n",
    "            q_text = row[\"question\"]\n",
    "            true_label = row[\"section\"]\n",
    "\n",
    "            q2s_blocks, s2q_blocks, q2q_blocks, s2s_blocks = attention_scores_for_question(\n",
    "                q_text,\n",
    "                sec_texts,\n",
    "                max_length=max_length,\n",
    "                batch_size=batch_size,\n",
    "                return_attention=True\n",
    "            )\n",
    "\n",
    "            obj = {\n",
    "                \"question_ind\": q_idx,\n",
    "                \"question\": q_text,\n",
    "                \"true_sections_label\": true_label,\n",
    "                \"q2s\": q2s_blocks,\n",
    "                \"s2q\": s2q_blocks,\n",
    "                \"q2q\": q2q_blocks,\n",
    "                \"s2s\": s2s_blocks,\n",
    "            }\n",
    "\n",
    "            pickle.dump(obj, f)\n",
    "\n",
    "        f.flush()\n",
    "        os.fsync(f.fileno())\n",
    "\n",
    "    print(\"\\nDone saving.\")\n",
    "\n",
    "def load_attention_blocks_stream(path=\"attention_blocks_stream.pkl\"):\n",
    "    blocks = []\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            try:\n",
    "                obj = pickle.load(f)\n",
    "                blocks.append(obj)\n",
    "            except EOFError:\n",
    "                break\n",
    "    return blocks    \n",
    "\n",
    "# collect_attention_blocks_stream(questions, sections, path=\"attention_blocks_stream.pkl\")\n",
    "all_attn_blocks = load_attention_blocks_stream(\"attention_blocks_stream.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0f4fcd1c-a80f-46af-bce2-780652174bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_fn(q2s, s2q, q2q=None, s2s=None):\n",
    "    # q2s_rm = q2s.max(axis=1).mean()\n",
    "    # s2q_rm = s2q.max(axis=1).mean()\n",
    "    # row_mean = float((q2s_rm + s2q_rm) / 2.0)\n",
    "    \n",
    "    cross_attention = (q2s.mean() + s2q.mean())\n",
    "    self_attention = (q2q.mean() + s2s.mean())\n",
    "    return float(cross_attention - self_attention)\n",
    "\n",
    "def get_scores_attention_from_blocks(q_idx):\n",
    "    entry = all_attn_blocks[q_idx]\n",
    "    q2s_blocks = entry[\"q2s\"]\n",
    "    s2q_blocks = entry[\"s2q\"]\n",
    "    q2q_blocks = entry['q2q']\n",
    "    s2s_blocks = entry['s2s']\n",
    "    \n",
    "    num_layers = len(q2s_blocks)\n",
    "    num_heads = len(q2s_blocks[0])\n",
    "    num_sections = len(q2s_blocks[0][0])\n",
    "\n",
    "    scores = np.zeros((num_layers, num_heads, num_sections), dtype=np.float32)\n",
    "\n",
    "    for l in range(num_layers):\n",
    "        for h in range(num_heads):\n",
    "            for s in range(num_sections):\n",
    "                q2s_block = q2s_blocks[l][h][s]\n",
    "                s2q_block = s2q_blocks[l][h][s]\n",
    "                q2q_block = q2q_blocks[l][h][s]\n",
    "                s2s_block = s2s_blocks[l][h][s]\n",
    "                scores[l, h, s] = score_fn(q2s_block, s2q_block, q2q_block, s2s_block)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bcd42651-74fd-476f-ad84-09892dc9cf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_attention(q_idx):\n",
    "    q_text = questions.question.tolist()[q_idx]\n",
    "    sec_texts = sections.text.tolist()\n",
    "\n",
    "    scores = attention_scores_for_question(\n",
    "        q_text,\n",
    "        sec_texts,\n",
    "        max_length=256,\n",
    "        batch_size=8\n",
    "    )  \n",
    "    return scores\n",
    "\n",
    "def rank_sections_attention(q_idx):\n",
    "    q_text = questions.question.tolist()[q_idx]\n",
    "    sec_texts = sections.text.tolist()\n",
    "\n",
    "    scores = attention_scores_for_question(\n",
    "        q_text,\n",
    "        sec_texts,\n",
    "        max_length=256,\n",
    "        batch_size=8\n",
    "    )\n",
    "\n",
    "    ranked = np.argsort(-scores) # (layers, heads, ranks)\n",
    "    return ranked\n",
    "\n",
    "def top_n_sections_attention(q_idx, n_sections):\n",
    "    ranks = rank_sections_attention(q_idx)\n",
    "    return ranks[:n_sections]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a097f02-9f73-4273-9df0-21e552d3150f",
   "metadata": {},
   "source": [
    "# Create And Save Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a2579455-d3e3-4b5e-8ab7-f951d183d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createScoresDf(save=True):\n",
    "    num_questions = len(questions)\n",
    "    all_dfs = []\n",
    "    for q in range(num_questions):\n",
    "        attention_scores = get_scores_attention_from_blocks(q)\n",
    "        \n",
    "        tfidf_scores = get_scores_tfidf(q)\n",
    "\n",
    "        results = {'question_ind':q, 'section': sections['section_number'].values,'tfidf': tfidf_scores}\n",
    "        for l,layer in enumerate(attention_scores):\n",
    "            for h,head_scores in enumerate(layer):\n",
    "                results[f\"attention_{l}_{h}\"] = head_scores\n",
    "        all_dfs.append(pd.DataFrame(results))\n",
    "    \n",
    "    scores = pd.concat(all_dfs)\n",
    "    if save:\n",
    "        scores.to_csv('scores.csv', index=False)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a57c1b56-ddfe-4df2-9d29-408031f1307b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_ind</th>\n",
       "      <th>section</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>attention_0_0</th>\n",
       "      <th>attention_0_1</th>\n",
       "      <th>attention_0_2</th>\n",
       "      <th>attention_0_3</th>\n",
       "      <th>attention_0_4</th>\n",
       "      <th>attention_0_5</th>\n",
       "      <th>attention_0_6</th>\n",
       "      <th>...</th>\n",
       "      <th>attention_5_2</th>\n",
       "      <th>attention_5_3</th>\n",
       "      <th>attention_5_4</th>\n",
       "      <th>attention_5_5</th>\n",
       "      <th>attention_5_6</th>\n",
       "      <th>attention_5_7</th>\n",
       "      <th>attention_5_8</th>\n",
       "      <th>attention_5_9</th>\n",
       "      <th>attention_5_10</th>\n",
       "      <th>attention_5_11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.141959</td>\n",
       "      <td>-0.001850</td>\n",
       "      <td>-0.003470</td>\n",
       "      <td>-0.030337</td>\n",
       "      <td>-0.032375</td>\n",
       "      <td>-0.000245</td>\n",
       "      <td>-0.010635</td>\n",
       "      <td>-0.005902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010182</td>\n",
       "      <td>-0.005750</td>\n",
       "      <td>-0.016651</td>\n",
       "      <td>-0.012952</td>\n",
       "      <td>-0.002663</td>\n",
       "      <td>-0.004979</td>\n",
       "      <td>-0.013655</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>-0.008556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>0.068223</td>\n",
       "      <td>-0.003319</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.034703</td>\n",
       "      <td>-0.040875</td>\n",
       "      <td>-0.001435</td>\n",
       "      <td>-0.016360</td>\n",
       "      <td>-0.010439</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009765</td>\n",
       "      <td>-0.004754</td>\n",
       "      <td>-0.015211</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>-0.002073</td>\n",
       "      <td>-0.003183</td>\n",
       "      <td>-0.013406</td>\n",
       "      <td>-0.006263</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.005264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.2</td>\n",
       "      <td>0.064733</td>\n",
       "      <td>-0.001663</td>\n",
       "      <td>-0.003967</td>\n",
       "      <td>-0.030635</td>\n",
       "      <td>-0.032820</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>-0.010789</td>\n",
       "      <td>-0.006206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010911</td>\n",
       "      <td>-0.006617</td>\n",
       "      <td>-0.016391</td>\n",
       "      <td>-0.012922</td>\n",
       "      <td>-0.002704</td>\n",
       "      <td>-0.005267</td>\n",
       "      <td>-0.016693</td>\n",
       "      <td>-0.005858</td>\n",
       "      <td>-0.004498</td>\n",
       "      <td>-0.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1.3</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>-0.001984</td>\n",
       "      <td>-0.004018</td>\n",
       "      <td>-0.030571</td>\n",
       "      <td>-0.032302</td>\n",
       "      <td>-0.000135</td>\n",
       "      <td>-0.010756</td>\n",
       "      <td>-0.006233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007984</td>\n",
       "      <td>-0.004231</td>\n",
       "      <td>-0.014007</td>\n",
       "      <td>-0.009952</td>\n",
       "      <td>-0.001873</td>\n",
       "      <td>-0.002845</td>\n",
       "      <td>-0.008911</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>-0.003308</td>\n",
       "      <td>-0.005151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.200803</td>\n",
       "      <td>-0.002420</td>\n",
       "      <td>-0.012149</td>\n",
       "      <td>-0.047518</td>\n",
       "      <td>-0.055708</td>\n",
       "      <td>-0.003121</td>\n",
       "      <td>-0.024479</td>\n",
       "      <td>-0.017048</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>-0.003648</td>\n",
       "      <td>-0.013043</td>\n",
       "      <td>-0.007568</td>\n",
       "      <td>-0.001790</td>\n",
       "      <td>-0.002649</td>\n",
       "      <td>-0.008857</td>\n",
       "      <td>-0.008659</td>\n",
       "      <td>-0.003660</td>\n",
       "      <td>-0.003903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>53</td>\n",
       "      <td>APPENDIX 11</td>\n",
       "      <td>0.028444</td>\n",
       "      <td>-0.004507</td>\n",
       "      <td>-0.016231</td>\n",
       "      <td>-0.063943</td>\n",
       "      <td>-0.070457</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.029509</td>\n",
       "      <td>-0.014686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018455</td>\n",
       "      <td>-0.009574</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>-0.013489</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>-0.004132</td>\n",
       "      <td>-0.038567</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>-0.008294</td>\n",
       "      <td>-0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>53</td>\n",
       "      <td>APPENDIX 12</td>\n",
       "      <td>0.016162</td>\n",
       "      <td>-0.004033</td>\n",
       "      <td>-0.005404</td>\n",
       "      <td>-0.054783</td>\n",
       "      <td>-0.054713</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.020555</td>\n",
       "      <td>-0.011267</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024386</td>\n",
       "      <td>-0.010943</td>\n",
       "      <td>-0.020207</td>\n",
       "      <td>-0.014436</td>\n",
       "      <td>-0.002883</td>\n",
       "      <td>-0.008998</td>\n",
       "      <td>-0.036962</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.008568</td>\n",
       "      <td>-0.007757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>53</td>\n",
       "      <td>APPENDIX 13</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>-0.005041</td>\n",
       "      <td>-0.012235</td>\n",
       "      <td>-0.059614</td>\n",
       "      <td>-0.065577</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>-0.027671</td>\n",
       "      <td>-0.013460</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018101</td>\n",
       "      <td>-0.009892</td>\n",
       "      <td>-0.017657</td>\n",
       "      <td>-0.011195</td>\n",
       "      <td>-0.001658</td>\n",
       "      <td>-0.003830</td>\n",
       "      <td>-0.031453</td>\n",
       "      <td>-0.017844</td>\n",
       "      <td>-0.006732</td>\n",
       "      <td>-0.005284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>53</td>\n",
       "      <td>APPENDIX 14</td>\n",
       "      <td>0.163219</td>\n",
       "      <td>-0.001838</td>\n",
       "      <td>-0.004411</td>\n",
       "      <td>-0.054257</td>\n",
       "      <td>-0.052804</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>-0.018213</td>\n",
       "      <td>-0.008228</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017061</td>\n",
       "      <td>-0.008809</td>\n",
       "      <td>-0.019528</td>\n",
       "      <td>-0.012614</td>\n",
       "      <td>-0.002043</td>\n",
       "      <td>-0.003192</td>\n",
       "      <td>-0.024365</td>\n",
       "      <td>-0.011895</td>\n",
       "      <td>-0.006417</td>\n",
       "      <td>-0.004770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>53</td>\n",
       "      <td>APPENDIX 15</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>-0.004982</td>\n",
       "      <td>-0.018481</td>\n",
       "      <td>-0.066843</td>\n",
       "      <td>-0.073301</td>\n",
       "      <td>-0.001738</td>\n",
       "      <td>-0.031943</td>\n",
       "      <td>-0.019333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019332</td>\n",
       "      <td>-0.009326</td>\n",
       "      <td>-0.018962</td>\n",
       "      <td>-0.013836</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.003987</td>\n",
       "      <td>-0.038837</td>\n",
       "      <td>-0.018694</td>\n",
       "      <td>-0.008858</td>\n",
       "      <td>-0.006094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6210 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     question_ind      section     tfidf  attention_0_0  attention_0_1  \\\n",
       "0               0          1.1  0.141959      -0.001850      -0.003470   \n",
       "1               0      1.1.1.1  0.068223      -0.003319      -0.008449   \n",
       "2               0        1.1.2  0.064733      -0.001663      -0.003967   \n",
       "3               0        1.1.3  0.133600      -0.001984      -0.004018   \n",
       "4               0          1.2  0.200803      -0.002420      -0.012149   \n",
       "..            ...          ...       ...            ...            ...   \n",
       "110            53  APPENDIX 11  0.028444      -0.004507      -0.016231   \n",
       "111            53  APPENDIX 12  0.016162      -0.004033      -0.005404   \n",
       "112            53  APPENDIX 13  0.060854      -0.005041      -0.012235   \n",
       "113            53  APPENDIX 14  0.163219      -0.001838      -0.004411   \n",
       "114            53  APPENDIX 15  0.053756      -0.004982      -0.018481   \n",
       "\n",
       "     attention_0_2  attention_0_3  attention_0_4  attention_0_5  \\\n",
       "0        -0.030337      -0.032375      -0.000245      -0.010635   \n",
       "1        -0.034703      -0.040875      -0.001435      -0.016360   \n",
       "2        -0.030635      -0.032820      -0.000059      -0.010789   \n",
       "3        -0.030571      -0.032302      -0.000135      -0.010756   \n",
       "4        -0.047518      -0.055708      -0.003121      -0.024479   \n",
       "..             ...            ...            ...            ...   \n",
       "110      -0.063943      -0.070457      -0.001955      -0.029509   \n",
       "111      -0.054783      -0.054713      -0.000499      -0.020555   \n",
       "112      -0.059614      -0.065577      -0.002125      -0.027671   \n",
       "113      -0.054257      -0.052804       0.000085      -0.018213   \n",
       "114      -0.066843      -0.073301      -0.001738      -0.031943   \n",
       "\n",
       "     attention_0_6  ...  attention_5_2  attention_5_3  attention_5_4  \\\n",
       "0        -0.005902  ...      -0.010182      -0.005750      -0.016651   \n",
       "1        -0.010439  ...      -0.009765      -0.004754      -0.015211   \n",
       "2        -0.006206  ...      -0.010911      -0.006617      -0.016391   \n",
       "3        -0.006233  ...      -0.007984      -0.004231      -0.014007   \n",
       "4        -0.017048  ...      -0.009816      -0.003648      -0.013043   \n",
       "..             ...  ...            ...            ...            ...   \n",
       "110      -0.014686  ...      -0.018455      -0.009574      -0.021246   \n",
       "111      -0.011267  ...      -0.024386      -0.010943      -0.020207   \n",
       "112      -0.013460  ...      -0.018101      -0.009892      -0.017657   \n",
       "113      -0.008228  ...      -0.017061      -0.008809      -0.019528   \n",
       "114      -0.019333  ...      -0.019332      -0.009326      -0.018962   \n",
       "\n",
       "     attention_5_5  attention_5_6  attention_5_7  attention_5_8  \\\n",
       "0        -0.012952      -0.002663      -0.004979      -0.013655   \n",
       "1        -0.011014      -0.002073      -0.003183      -0.013406   \n",
       "2        -0.012922      -0.002704      -0.005267      -0.016693   \n",
       "3        -0.009952      -0.001873      -0.002845      -0.008911   \n",
       "4        -0.007568      -0.001790      -0.002649      -0.008857   \n",
       "..             ...            ...            ...            ...   \n",
       "110      -0.013489      -0.001125      -0.004132      -0.038567   \n",
       "111      -0.014436      -0.002883      -0.008998      -0.036962   \n",
       "112      -0.011195      -0.001658      -0.003830      -0.031453   \n",
       "113      -0.012614      -0.002043      -0.003192      -0.024365   \n",
       "114      -0.013836      -0.001247      -0.003987      -0.038837   \n",
       "\n",
       "     attention_5_9  attention_5_10  attention_5_11  \n",
       "0        -0.005167       -0.004561       -0.008556  \n",
       "1        -0.006263       -0.003729       -0.005264  \n",
       "2        -0.005858       -0.004498       -0.008793  \n",
       "3        -0.004988       -0.003308       -0.005151  \n",
       "4        -0.008659       -0.003660       -0.003903  \n",
       "..             ...             ...             ...  \n",
       "110      -0.016195       -0.008294       -0.006900  \n",
       "111      -0.011540       -0.008568       -0.007757  \n",
       "112      -0.017844       -0.006732       -0.005284  \n",
       "113      -0.011895       -0.006417       -0.004770  \n",
       "114      -0.018694       -0.008858       -0.006094  \n",
       "\n",
       "[6210 rows x 75 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = createScoresDf()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250119c-c5cd-4a7a-a6bf-da4755e199a5",
   "metadata": {},
   "source": [
    "# Testing & Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "de1292aa-21e2-47de-9d1d-0a04aace0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer_mean_attention_scores(scores):\n",
    "    attention_cols = [c for c in scores.columns if c.startswith(\"attention_\") and \"layer\" not in c]\n",
    "    layer_to_cols = {}\n",
    "\n",
    "    for col in attention_cols:\n",
    "        parts = col.split(\"_\")\n",
    "        if len(parts) != 3:\n",
    "            continue\n",
    "        \n",
    "        _, layer_str, head_str = parts\n",
    "        layer = int(layer_str)\n",
    "\n",
    "        if layer not in layer_to_cols:\n",
    "            layer_to_cols[layer] = []\n",
    "        layer_to_cols[layer].append(col)\n",
    "\n",
    "    for layer, cols in layer_to_cols.items():\n",
    "        layer_col = f\"attention_{layer}\"\n",
    "        scores[layer_col] = scores[cols].mean(axis=1)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7fde0609-987e-4369-885e-466a19979c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add_layer_mean_attention_scores(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "641938e6-dc10-484a-a8e3-4a7447e5e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_accuracy_for_method(scores, questions, method_col, top_n=1):\n",
    "    num_questions = len(questions)\n",
    "    correct = 0\n",
    "\n",
    "    for q_idx in range(num_questions):\n",
    "        df_q = scores[scores[\"question_ind\"] == q_idx]\n",
    "        top_rows = df_q[method_col].nlargest(top_n).index\n",
    "        pred_secs = df_q.loc[top_rows, \"section\"].tolist()\n",
    "        true_secs = questions.loc[q_idx, \"section\"]\n",
    "        if any(p in true_secs for p in pred_secs):\n",
    "            correct += 1\n",
    "\n",
    "    return correct / num_questions\n",
    "\n",
    "\n",
    "def compute_top_n_accuracy(scores, questions, method_cols=None, top_n = 1):\n",
    "    if method_cols is None:\n",
    "        method_cols = [\n",
    "            c for c in scores.columns\n",
    "            if c not in [\"question_ind\", \"section\"]\n",
    "        ]\n",
    "\n",
    "    rows = []\n",
    "    for method in method_cols:\n",
    "        acc = top_n_accuracy_for_method(scores, questions, method, top_n)\n",
    "        rows.append({\"method\": method, f\"top_{top_n}_accuracy\": acc})\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(f\"top_{top_n}_accuracy\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3b4b802c-ff4e-4b91-b112-437349afddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1_df = compute_top_n_accuracy(results, questions, top_n=1)\n",
    "acc_3_df = compute_top_n_accuracy(results, questions, top_n=3)\n",
    "acc_5_df = compute_top_n_accuracy(results, questions, top_n=5)\n",
    "\n",
    "acc_df = (\n",
    "    acc_1_df\n",
    "    .merge(acc_3_df[[\"method\", \"top_3_accuracy\"]], on=\"method\", how=\"outer\")\n",
    "    .merge(acc_5_df[[\"method\", \"top_5_accuracy\"]], on=\"method\", how=\"outer\")\n",
    ").sort_values(\"top_1_accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9d9ed506-c5bc-4750-92e7-878d776b3b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>top_1_accuracy</th>\n",
       "      <th>top_3_accuracy</th>\n",
       "      <th>top_5_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>attention_1_6</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>attention_5_4</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.574074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attention_0_9</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.685185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>attention_4_7</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>attention_1_3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>attention_1_5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>attention_1_7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>attention_1_9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.092593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>attention_4_11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            method  top_1_accuracy  top_3_accuracy  top_5_accuracy\n",
       "72           tfidf        0.500000        0.814815        0.851852\n",
       "20   attention_1_6        0.444444        0.685185        0.703704\n",
       "66   attention_5_4        0.370370        0.518519        0.574074\n",
       "11   attention_0_9        0.370370        0.592593        0.685185\n",
       "57   attention_4_7        0.333333        0.555556        0.703704\n",
       "..             ...             ...             ...             ...\n",
       "17   attention_1_3        0.000000        0.000000        0.000000\n",
       "19   attention_1_5        0.000000        0.055556        0.092593\n",
       "21   attention_1_7        0.000000        0.074074        0.092593\n",
       "23   attention_1_9        0.000000        0.037037        0.092593\n",
       "51  attention_4_11        0.000000        0.000000        0.037037\n",
       "\n",
       "[73 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f9d14d-50d3-4038-8523-aae4af31c681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
